{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5c9a4acec841c9ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "0. Download sequence and structure files from ZINC-downloader-3D-{smi}/{sdf.gz}.uri"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c50b80cb20777f6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# run the following in the terminal (remove the \"!\" at the first)\n",
    "!wget -i ZINC-downloader-3D-sdf.gz.uri -P ./sdf\n",
    "!wget -i ZINC-downloader-3D-smi.uri -P ./smile"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cf574b5e9e9bc1f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Extract SMILES sequence from .smi format files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f52e4dce420e5163"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "input_folder = \"./smile\"\n",
    "output_file = \"./zinc_SMILES.csv\"\n",
    "all_data = []\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".smi\"):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines[0:]:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 2:\n",
    "                    smiles = parts[0]\n",
    "                    zinc_id = parts[1]\n",
    "                    all_data.append([zinc_id, smiles])\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['zinc_id', 'smiles'])\n",
    "    writer.writerows(all_data)\n",
    "\n",
    "print(f\"数据已成功整合到 {output_file}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a56d7d32c453d57c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Unzip .sdf.gz files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e6b9599f6a2e246"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# 设置文件夹路径（替换为你的路径）\n",
    "folder_path = \"./sdf\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".sdf.gz\"):\n",
    "        # 构建完整文件路径\n",
    "        gz_path = os.path.join(folder_path, filename)\n",
    "        # 生成解压后的文件名（去掉.gz后缀）\n",
    "        output_name = filename[:-3]  # 假设文件名类似 BAAAMO.xaa.sdf.gz\n",
    "        output_path = os.path.join('./structure', output_name)\n",
    "\n",
    "        # 执行解压\n",
    "        with gzip.open(gz_path, 'rb') as f_in:\n",
    "            with open(output_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        print(f\"解压完成: {filename} → {output_name}\")\n",
    "\n",
    "print(\"所有文件已处理完毕！\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dd2c535c6e8a888"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Split sdf files (This is necessary, because the sdf files contain many molecules in a file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3730450468ba3d08"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def split_sdf(input_folder, output_folder):\n",
    "    # 确保输出文件夹存在\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 遍历输入文件夹中的所有文件\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".sdf\"):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            with open(input_path, 'r') as f:\n",
    "                current_molecule = []\n",
    "                zinc_id = None\n",
    "\n",
    "                for line in f:\n",
    "                    current_molecule.append(line)\n",
    "\n",
    "                    # 检测分子开始\n",
    "                    if line.startswith(\"ZINC\"):\n",
    "                        zinc_id = line.strip().split()[0]  # 提取ZINC ID\n",
    "\n",
    "                    # 检测分子结束\n",
    "                    if line.strip() == \"$$$$\":\n",
    "                        # 写入文件\n",
    "                        output_path = os.path.join(output_folder, f\"{zinc_id}.sdf\")\n",
    "                        with open(output_path, 'w') as out_file:\n",
    "                            out_file.writelines(current_molecule)\n",
    "\n",
    "                        # 重置临时存储\n",
    "                        current_molecule = []\n",
    "                        zinc_id = None\n",
    "# 使用示例\n",
    "split_sdf(\"./structure\", \"./zinc_sdf\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b60e96d0161d8f2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Construct input molecule file (in a format of .pkl.gz)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f9f5ae3bc33812b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# run \"python preprocess_mol_pkl.py\" in the ./zinc file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5323d1bf8a15e2c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Make sure SMILES sequence and molecule structure have the same ID"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a31a81b329ca089d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "# 定义文件路径\n",
    "pkl_file_path = \"../mol_structures.pkl.gz\"\n",
    "csv_file_path = \"zinc_SMILES.csv\"\n",
    "output_file_path = \"filtered_zinc_SMILES.csv\"\n",
    "\n",
    "# 获取 JSON 文件中的所有 ID\n",
    "def load_dict(input_path):\n",
    "    with gzip.open(input_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "data = load_dict(pkl_file_path)\n",
    "ids = set(data.keys())\n",
    "print(f\"pkl 文件中不同 ID 的数量: {len(ids)}\")\n",
    "\n",
    "# 筛选 CSV 文件中与 JSON 文件具有相同 ID 的项\n",
    "with open(csv_file_path, 'r') as csv_file, open(output_file_path, 'w', newline='') as output_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    csv_writer = csv.DictWriter(output_file, fieldnames=csv_reader.fieldnames)\n",
    "    csv_writer.writeheader()\n",
    "\n",
    "    matched_ids = set()\n",
    "    for row in csv_reader:\n",
    "        zinc_id = row.get('zinc_id')\n",
    "        if zinc_id and zinc_id in ids:\n",
    "            csv_writer.writerow(row)\n",
    "            matched_ids.add(zinc_id)\n",
    "\n",
    "    print(f\"CSV 文件中匹配的 ID 数量: {len(matched_ids)}\")\n",
    "    print(f\"筛选后的 CSV 文件已保存到 {output_file_path}\")\n",
    "\n",
    "# 验证两者所包含的 ID 是否一致\n",
    "print(f\"pkl 文件中的 ID 数量: {len(ids)}\")\n",
    "print(f\"筛选后的 CSV 文件中的 ID 数量: {len(matched_ids)}\")\n",
    "print(f\"两者所包含的 ID 是否一致: {len(ids) == len(matched_ids)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a233d385d5b431ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Extract protein pocket information"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8609ae0439c929fa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Batch acquisition of protein sequence, pocket sequence, and absolute position information of pockets\n",
    "import pandas as pd\n",
    "def get_poc_seq(pocket_path, protein_path):\n",
    "    aa_codes = {\n",
    "        'ALA':'A', 'CYS':'C', 'ASP':'D', 'GLU':'E',\n",
    "        'PHE':'F', 'GLY':'G', 'HIS':'H', 'LYS':'K',\n",
    "        'ILE':'I', 'LEU':'L', 'MET':'M', 'ASN':'N',\n",
    "        'PRO':'P', 'GLN':'Q', 'ARG':'R', 'SER':'S',\n",
    "        'THR':'T', 'VAL':'V', 'TYR':'Y', 'TRP':'W'}\n",
    "    poc_seq = ''\n",
    "    i = ''  # locator\n",
    "    position = []\n",
    "    protein_seq, order = get_pro_seq(protein_path)\n",
    "    for line in open(pocket_path):\n",
    "        if line[0:4] == \"ATOM\":\n",
    "            columns = line.split()\n",
    "            index1 = columns[4]\n",
    "            index2 = columns[5]\n",
    "            if len(columns[4]) > 1: # When the residue sequence exceeds 1000, there will be no spaces between the chain and sequence, and manual separation is required\n",
    "                index1 = columns[4][0]\n",
    "                index2 = columns[4][1:]\n",
    "            if index2 != i:\n",
    "                i = index2\n",
    "                position.append(order[(index1, index2)])\n",
    "                poc_seq += aa_codes.get(columns[3], 'X')\n",
    "            else:\n",
    "                continue\n",
    "    return protein_seq, poc_seq, position\n",
    "\n",
    "# This module is used to obtain the absolute position information of the entire protein sequence and pockets\n",
    "def get_pro_seq(path):\n",
    "    aa_codes = {\n",
    "        'ALA': 'A', 'CYS': 'C', 'ASP': 'D', 'GLU': 'E',\n",
    "        'PHE': 'F', 'GLY': 'G', 'HIS': 'H', 'LYS': 'K',\n",
    "        'ILE': 'I', 'LEU': 'L', 'MET': 'M', 'ASN': 'N',\n",
    "        'PRO': 'P', 'GLN': 'Q', 'ARG': 'R', 'SER': 'S',\n",
    "        'THR': 'T', 'VAL': 'V', 'TYR': 'Y', 'TRP': 'W'}\n",
    "    seq = ''\n",
    "    order = {}\n",
    "    i = 0  # locator\n",
    "    for line in open(path):\n",
    "        if line[0:4] == \"ATOM\":\n",
    "            columns = line.split()\n",
    "            index1 = columns[4]\n",
    "            index2 = columns[5]\n",
    "            if len(columns[4]) > 1: # When the residue sequence exceeds 1000, there will be no spaces between the chain and sequence, and manual separation is required\n",
    "                index1 = columns[4][0]\n",
    "                index2 = columns[4][1:]\n",
    "            if (index1, index2) not in order:\n",
    "                i = i + 1\n",
    "                order[(index1, index2)] = i\n",
    "                seq += aa_codes.get(columns[3], 'X')\n",
    "            else:\n",
    "                continue\n",
    "    return seq, order\n",
    "\n",
    "pocket_file_path = '../case_study_CB1R/alphafold_DoGsite3_pocket.pdb'\n",
    "protein_file_path = '../case_study_CB1R/alphafold_protein.pdb'\n",
    "\n",
    "protein_seq, pocket_seq, position = get_poc_seq(pocket_file_path, protein_file_path)\n",
    "print(pocket_seq)\n",
    "print(position)\n",
    "print(protein_seq)\n",
    "print(len(protein_seq), len(pocket_seq))\n",
    "\n",
    "# 读取 CSV 文件\n",
    "file_path = \"./filtered_zinc_SMILES.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 将 position 列表转换为字符串\n",
    "position_str = ', '.join(map(str, position))  # 将列表元素转换为字符串并用逗号和空格分隔\n",
    "position = f'[{position_str}]'  # 添加方括号\n",
    "\n",
    "# 替换第三列（假设列索引为 2，因为 Python 是从 0 开始计数的）\n",
    "df.insert(2, 'protein', protein_seq)\n",
    "df.insert(3, 'pocket', pocket_seq)\n",
    "df.insert(4, 'position', position)\n",
    "\n",
    "# 保存到新的 CSV 文件\n",
    "output_file_path = \"../processed_zinc_CB1R.csv\"\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"文件已成功更新,结果保存在 {output_file_path}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96352af2e816bdb6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Construct input protein file (in a format of .pkl.gz)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c421cdc7cbe27a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "def save_dict(mol_dict, output_path):\n",
    "    with gzip.open(output_path, 'wb') as f:\n",
    "        pickle.dump(mol_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "AA_MAP = {\n",
    "    'ALA': 'A', 'CYS': 'C', 'ASP': 'D', 'GLU': 'E', 'PHE': 'F', 'GLY': 'G',\n",
    "    'HIS': 'H', 'ILE': 'I', 'LYS': 'K', 'LEU': 'L', 'MET': 'M', 'ASN': 'N',\n",
    "    'PRO': 'P', 'GLN': 'Q', 'ARG': 'R', 'SER': 'S', 'THR': 'T', 'VAL': 'V',\n",
    "    'TRP': 'W', 'TYR': 'Y',  # 20种标准氨基酸\n",
    "    'SEC': 'U',  # 硒代半胱氨酸 (Selenocysteine)\n",
    "    'PYL': 'O',  # 吡咯赖氨酸 (Pyrrolysine)\n",
    "    'HYP': 'B',  # 羟脯氨酸 (Hydroxyproline) 将其从原本的'X'改为'B'，可以避免与未知氨基酸的冲突\n",
    "    'SEP': 'Z',  # 磷酸丝氨酸 (Phosphoserine)\n",
    "    'TPO': 'J'   # 磷酸酪氨酸 (Phosphotyrosine)\n",
    "}\n",
    "\n",
    "def three_to_one_coords(aa_three_letter):\n",
    "    # 对于非常见的20种氨基酸，返回 'X'\n",
    "    return AA_MAP.get(aa_three_letter, 'X')\n",
    "\n",
    "def three_to_one_seq(aa_three_letter):\n",
    "    # 如果是常见的20种氨基酸，返回其单字母表示；否则，返回 None\n",
    "    return AA_MAP.get(aa_three_letter, None)\n",
    "\n",
    "def extract_protein_coords_and_seq_from_pdb(pdb_file_path):\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"protein\", pdb_file_path)\n",
    "    protein_sequence = []\n",
    "    coords = {'N': [], 'CA': [], 'C': [], 'O': []}\n",
    "\n",
    "    for residue in structure.get_residues():\n",
    "        if residue.has_id('CA'):\n",
    "            aa_three_letter = residue.get_resname()\n",
    "            aa_one_letter_seq = three_to_one_seq(aa_three_letter)\n",
    "            if aa_one_letter_seq:  # 如果不是 None，即不是非标准氨基酸\n",
    "                protein_sequence.append(aa_one_letter_seq)\n",
    "            aa_one_letter_coords = three_to_one_coords(aa_three_letter)\n",
    "            if aa_one_letter_coords == 'X':  # 如果是非标准氨基酸\n",
    "                continue\n",
    "            for atom in residue:\n",
    "                if atom.name.strip() in ['N', 'CA', 'C', 'O']:\n",
    "                    coord = list(round(float(x), 3) for x in atom.coord)\n",
    "                    coords[atom.name.strip()].append(coord)\n",
    "                    # coords[atom.name.strip()].append(list(atom.coord))\n",
    "            coords = {k: [list(item) for item in v] for k, v in coords.items()}\n",
    "\n",
    "    return coords, ''.join(protein_sequence)\n",
    "\n",
    "pdb_data_dir='../case_study_CB1R/alphafold_DoGsite3_pocket.pdb'\n",
    "output_pkl_path = f'../pocket_structures.pkl.gz'\n",
    "coords, protein_sequence = extract_protein_coords_and_seq_from_pdb(pdb_data_dir)\n",
    "assert (len(coords['CA']) == len(protein_sequence) and len(coords['N']) == len(coords['C']) and\n",
    "        len(coords['CA']) == len(coords['C']) and len(coords['N']) == len(coords['O']))\n",
    "protein_dict = {'target': {\n",
    "    'seq': protein_sequence,\n",
    "    'coords': coords\n",
    "}}\n",
    "save_dict(protein_dict, output_pkl_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90f23f384cbaf0e3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
